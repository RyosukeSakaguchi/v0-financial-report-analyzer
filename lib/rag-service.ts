import { createClient } from "@/lib/supabase-client"
import { generateText, embed } from "ai"
import { openai } from "@ai-sdk/openai"

// PDFã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
interface DocumentChunk {
  id: string
  content: string
  embedding?: number[]
  metadata: {
    documentId: number
    filename: string
    page: number
    url: string
    section?: string
  }
}

// RAGã®çµæœã‚’è¡¨ã™ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
interface RagResult {
  answer: string
  sources: {
    filename: string
    page: number
    text: string
    url: string
  }[]
  selectedDocuments: string[]
  debugInfo?: any
}

// AI SDKã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
async function createEmbedding(text: string): Promise<number[]> {
  try {
    // API ã‚­ãƒ¼ã®ç¢ºèª
    const apiKey = process.env.OPENAI_API_KEY
    if (!apiKey) {
      console.warn("OpenAI API key not found, skipping embedding creation")
      return []
    }

    console.log("AI SDKã§embeddingã‚’ä½œæˆä¸­...")

    // OpenAI providerã«API keyã‚’æ˜ç¤ºçš„ã«æ¸¡ã™
    const openaiProvider = openai({
      apiKey: apiKey,
    })

    const { embedding } = await embed({
      model: openaiProvider.embedding("text-embedding-3-small"),
      value: text,
    })

    console.log(`Embeddingä½œæˆæˆåŠŸ: ${embedding.length}æ¬¡å…ƒ`)
    return embedding
  } catch (error) {
    console.error("Embedding creation error:", error)
    console.log("Embeddingã®ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
    return []
  }
}

// ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
function cosineSimilarity(a: number[], b: number[]): number {
  if (a.length !== b.length) {
    throw new Error("ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒãŒä¸€è‡´ã—ã¾ã›ã‚“")
  }

  let dotProduct = 0
  let normA = 0
  let normB = 0

  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i]
    normA += a[i] * a[i]
    normB += b[i] * b[i]
  }

  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB))
}

// ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
async function getUploadedDocuments(selectedDocIds: number[]) {
  const supabase = createClient()

  const { data, error } = await supabase
    .from("documents")
    .select("id, filename, url, status, size, created_at")
    .in("id", selectedDocIds)
    .eq("status", "completed")

  if (error) {
    console.error("Error fetching documents:", error)
    return []
  }

  return data || []
}

// ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆãƒ™ã‚¯ãƒˆãƒ«ä»˜ãï¼‰
async function getDocumentChunks(selectedDocIds: number[]): Promise<DocumentChunk[]> {
  const supabase = createClient()

  try {
    console.log("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ä¸­...")

    const { data: chunks, error } = await supabase
      .from("document_chunks")
      .select("*")
      .in("document_id", selectedDocIds)
      .order("document_id, page")

    if (error) {
      console.error("Database error:", error)
      throw new Error(`ãƒãƒ£ãƒ³ã‚¯ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error.message}`)
    }

    if (!chunks || chunks.length === 0) {
      console.log("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
      return []
    }

    console.log(`ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰${chunks.length}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ã—ã¾ã—ãŸ`)

    // ãƒãƒ£ãƒ³ã‚¯ã‚’DocumentChunkå½¢å¼ã«å¤‰æ›
    const documentChunks: DocumentChunk[] = await Promise.all(
      chunks.map(async (chunk) => {
        let embedding: number[] | undefined

        // æ—¢å­˜ã®embeddingãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if (chunk.embedding && Array.isArray(chunk.embedding)) {
          embedding = chunk.embedding
          console.log(`ãƒãƒ£ãƒ³ã‚¯ ${chunk.id}: æ—¢å­˜ã®embeddingã‚’ä½¿ç”¨`)
        } else {
          // embeddingãŒãªã„å ´åˆã¯æ–°ã—ãä½œæˆï¼ˆAPI keyãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
          if (process.env.OPENAI_API_KEY) {
            try {
              console.log(`ãƒãƒ£ãƒ³ã‚¯ ${chunk.id} ã®embeddingã‚’ä½œæˆä¸­...`)
              const embeddingResult = await createEmbedding(chunk.content)
              if (embeddingResult.length > 0) {
                embedding = embeddingResult
                // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«embeddingã‚’ä¿å­˜
                await supabase.from("document_chunks").update({ embedding }).eq("id", chunk.id)
                console.log(`ãƒãƒ£ãƒ³ã‚¯ ${chunk.id}: embeddingã‚’ä½œæˆãƒ»ä¿å­˜ã—ã¾ã—ãŸ`)
              }
            } catch (embeddingError) {
              console.error(`ãƒãƒ£ãƒ³ã‚¯ ${chunk.id} ã®embeddingä½œæˆã«å¤±æ•—:`, embeddingError)
              embedding = undefined
            }
          } else {
            console.log(`ãƒãƒ£ãƒ³ã‚¯ ${chunk.id}: OpenAI API keyãŒãªã„ãŸã‚embeddingã‚’ã‚¹ã‚­ãƒƒãƒ—`)
          }
        }

        return {
          id: chunk.id.toString(),
          content: chunk.content,
          embedding,
          metadata: {
            documentId: chunk.document_id,
            filename: chunk.filename || "Unknown",
            page: chunk.page || 1,
            url: chunk.source || "",
            section: `Page ${chunk.page}`,
          },
        }
      }),
    )

    const chunksWithEmbedding = documentChunks.filter((chunk) => chunk.embedding)
    console.log(`${chunksWithEmbedding.length}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«embeddingãŒè¨­å®šã•ã‚Œã¾ã—ãŸ`)

    // embeddingãŒãªã„ãƒãƒ£ãƒ³ã‚¯ã‚‚å«ã‚ã‚‹ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ç”¨ï¼‰
    return documentChunks
  } catch (error) {
    console.error("Error in getDocumentChunks:", error)
    return []
  }
}

// ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—
async function findRelevantChunksByVector(query: string, chunks: DocumentChunk[], limit = 5): Promise<DocumentChunk[]> {
  console.log(`\n=== ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ ===`)
  console.log(`æ¤œç´¢ã‚¯ã‚¨ãƒª: "${query}"`)
  console.log(`æ¤œç´¢å¯¾è±¡ãƒãƒ£ãƒ³ã‚¯æ•°: ${chunks.length}`)

  // embeddingãŒã‚ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ•ã‚£ãƒ«ã‚¿
  const chunksWithEmbedding = chunks.filter((chunk) => chunk.embedding)
  console.log(`embeddingä»˜ããƒãƒ£ãƒ³ã‚¯æ•°: ${chunksWithEmbedding.length}`)

  if (chunksWithEmbedding.length === 0 || !process.env.OPENAI_API_KEY) {
    console.log("ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
    return findRelevantChunksByKeyword(query, chunks, limit)
  }

  try {
    // è³ªå•ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    console.log("è³ªå•ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
    const queryEmbedding = await createEmbedding(query)

    if (queryEmbedding.length === 0) {
      console.log("è³ªå•ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«å¤±æ•—ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
      return findRelevantChunksByKeyword(query, chunks, limit)
    }

    console.log(`è³ªå•ã®ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ: ${queryEmbedding.length}`)

    // å„ãƒãƒ£ãƒ³ã‚¯ã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
    const scoredChunks = chunksWithEmbedding
      .map((chunk) => {
        const similarity = cosineSimilarity(queryEmbedding, chunk.embedding!)
        return { chunk, similarity }
      })
      .sort((a, b) => b.similarity - a.similarity) // é¡ä¼¼åº¦ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
      .slice(0, limit)

    console.log("ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœ:")
    scoredChunks.forEach((item, index) => {
      console.log(`${index + 1}. ãƒšãƒ¼ã‚¸ ${item.chunk.metadata.page} (é¡ä¼¼åº¦: ${item.similarity.toFixed(4)})`)
    })

    return scoredChunks.map((item) => item.chunk)
  } catch (error) {
    console.error("ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼:", error)
    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
    console.log("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œ")
    return findRelevantChunksByKeyword(query, chunks, limit)
  }
}

// æ”¹å–„ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
function findRelevantChunksByKeyword(query: string, chunks: DocumentChunk[], limit = 5): DocumentChunk[] {
  console.log("=== æ”¹å–„ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ ===")
  console.log(`æ¤œç´¢ã‚¯ã‚¨ãƒª: "${query}"`)

  const queryLower = query.toLowerCase()

  // ã‚ˆã‚ŠæŸ”è»Ÿãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
  const queryWords = queryLower
    .replace(/[^\w\s]/g, " ") // è¨˜å·ã‚’ç©ºç™½ã«ç½®æ›
    .split(/\s+/)
    .filter((word) => word.length > 1) // 1æ–‡å­—ä»¥ä¸Šã®å˜èªã‚’å¯¾è±¡
    .map((word) => word.trim())
    .filter((word) => word.length > 0)

  console.log(`æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: [${queryWords.join(", ")}]`)

  // è²¡å‹™é–¢é€£ã®åŒç¾©èªè¾æ›¸
  const synonyms: { [key: string]: string[] } = {
    balance: ["balance", "sheet", "statement", "financial", "position", "assets", "liabilities", "equity"],
    sheet: ["balance", "sheet", "statement", "financial", "position"],
    revenue: ["revenue", "sales", "income", "earnings", "turnover", "receipts"],
    profit: ["profit", "income", "earnings", "net", "operating"],
    cash: ["cash", "money", "liquid", "currency", "equivalents"],
    assets: ["assets", "property", "investments", "holdings", "resources"],
    liabilities: ["liabilities", "debt", "obligations", "payable"],
    equity: ["equity", "shareholders", "stockholders", "capital"],
    google: ["google", "alphabet", "goog", "googl"],
    apple: ["apple", "aapl", "iphone", "mac", "ipad"],
    æƒ…å ±: ["information", "data", "details", "info"],
    å–å¾—: ["get", "obtain", "retrieve", "extract", "find"],
    è²¡å‹™: ["financial", "finance", "fiscal", "monetary"],
    è²¸å€Ÿå¯¾ç…§è¡¨: ["balance", "sheet", "statement", "position"],
    æç›Šè¨ˆç®—æ›¸: ["income", "statement", "profit", "loss", "earnings"],
    ç¾é‡‘: ["cash", "money", "liquid", "currency"],
  }

  // æ‹¡å¼µã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’ä½œæˆ
  const expandedKeywords = new Set<string>()
  queryWords.forEach((word) => {
    expandedKeywords.add(word)
    // åŒç¾©èªã‚’è¿½åŠ 
    Object.entries(synonyms).forEach(([key, values]) => {
      if (word.includes(key) || key.includes(word)) {
        values.forEach((synonym) => expandedKeywords.add(synonym))
      }
    })
  })

  const allKeywords = Array.from(expandedKeywords)
  console.log(`æ‹¡å¼µã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: [${allKeywords.join(", ")}]`)

  const scoredChunks = chunks.map((chunk) => {
    let score = 0
    const contentLower = chunk.content.toLowerCase()
    const filename = chunk.metadata.filename.toLowerCase()

    // 1. å®Œå…¨ä¸€è‡´ãƒœãƒ¼ãƒŠã‚¹ï¼ˆé«˜ã‚¹ã‚³ã‚¢ï¼‰
    queryWords.forEach((word) => {
      if (word.length > 2) {
        const exactMatches = (contentLower.match(new RegExp(`\\b${word}\\b`, "g")) || []).length
        score += exactMatches * 20

        // ãƒ•ã‚¡ã‚¤ãƒ«åã§ã®ä¸€è‡´ã‚‚ãƒœãƒ¼ãƒŠã‚¹
        if (filename.includes(word)) {
          score += 15
        }
      }
    })

    // 2. æ‹¡å¼µã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã®ä¸€è‡´
    allKeywords.forEach((keyword) => {
      if (keyword.length > 2) {
        const matches = (contentLower.match(new RegExp(`\\b${keyword}\\b`, "g")) || []).length
        score += matches * 10
      }
    })

    // 3. éƒ¨åˆ†ä¸€è‡´
    queryWords.forEach((word) => {
      if (word.length > 3 && contentLower.includes(word)) {
        score += 5
      }
    })

    // 4. ç‰¹å®šã®è²¡å‹™ç”¨èªã«å¯¾ã™ã‚‹ç‰¹åˆ¥ãªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    if (queryLower.includes("balance") || queryLower.includes("sheet") || queryLower.includes("è²¸å€Ÿå¯¾ç…§è¡¨")) {
      const financialTerms = [
        "assets",
        "liabilities",
        "equity",
        "balance",
        "sheet",
        "financial",
        "position",
        "statement",
      ]
      financialTerms.forEach((term) => {
        if (contentLower.includes(term)) {
          score += 25
        }
      })
    }

    // 5. æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ãƒœãƒ¼ãƒŠã‚¹ï¼ˆè²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®å¯èƒ½æ€§ï¼‰
    const hasNumbers = /\$[\d,]+|\d+\.\d+|\d+%|\d+\s*(million|billion|thousand)/i.test(chunk.content)
    if (hasNumbers) {
      score += 10
    }

    // 6. ãƒšãƒ¼ã‚¸ç•ªå·ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘ï¼ˆå‰åŠã®ãƒšãƒ¼ã‚¸ã‚’é‡è¦–ï¼‰
    if (chunk.metadata.page <= 10) {
      score += 5
    }

    return { chunk, score, details: { exactMatches: score } }
  })

  const results = scoredChunks
    .filter((item) => item.score > 0)
    .sort((a, b) => b.score - a.score)
    .slice(0, limit)

  console.log("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢çµæœ:")
  results.forEach((item, index) => {
    console.log(`${index + 1}. ãƒšãƒ¼ã‚¸ ${item.chunk.metadata.page} (ã‚¹ã‚³ã‚¢: ${item.score})`)
    console.log(`   å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: ${item.chunk.content.substring(0, 100)}...`)
  })

  // ã‚¹ã‚³ã‚¢ãŒä½ã™ãã‚‹å ´åˆã¯ã€ã‚ˆã‚Šå¯›å®¹ãªæ¤œç´¢ã‚’å®Ÿè¡Œ
  if (results.length === 0 || results[0].score < 10) {
    console.log("ã‚¹ã‚³ã‚¢ãŒä½ã„ãŸã‚ã€ã‚ˆã‚Šå¯›å®¹ãªæ¤œç´¢ã‚’å®Ÿè¡Œ")
    return findRelevantChunksByLooseSearch(query, chunks, limit)
  }

  return results.map((item) => item.chunk)
}

// ã‚ˆã‚Šå¯›å®¹ãªæ¤œç´¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
function findRelevantChunksByLooseSearch(query: string, chunks: DocumentChunk[], limit = 5): DocumentChunk[] {
  console.log("=== å¯›å®¹ãªæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ ===")

  const queryLower = query.toLowerCase()

  // ä»»æ„ã®å˜èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’æ¢ã™
  const scoredChunks = chunks.map((chunk) => {
    let score = 0
    const contentLower = chunk.content.toLowerCase()

    // å˜ç´”ãªæ–‡å­—åˆ—åŒ…å«ãƒã‚§ãƒƒã‚¯
    const words = queryLower.split(/\s+/).filter((w) => w.length > 2)
    words.forEach((word) => {
      if (contentLower.includes(word)) {
        score += 1
      }
    })

    // è²¡å‹™é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯ãƒœãƒ¼ãƒŠã‚¹
    const financialKeywords = [
      "revenue",
      "income",
      "cash",
      "assets",
      "financial",
      "statement",
      "balance",
      "profit",
      "billion",
      "million",
    ]
    financialKeywords.forEach((keyword) => {
      if (contentLower.includes(keyword)) {
        score += 3
      }
    })

    return { chunk, score }
  })

  const results = scoredChunks
    .filter((item) => item.score > 0)
    .sort((a, b) => b.score - a.score)
    .slice(0, limit)

  console.log(`å¯›å®¹ãªæ¤œç´¢ã§${results.length}å€‹ã®çµæœã‚’ç™ºè¦‹`)

  // ãã‚Œã§ã‚‚çµæœãŒãªã„å ´åˆã¯ã€æœ€åˆã®æ•°ãƒšãƒ¼ã‚¸ã‚’è¿”ã™
  if (results.length === 0) {
    console.log("æ¤œç´¢çµæœãªã—ã€‚æœ€åˆã®5ãƒšãƒ¼ã‚¸ã‚’è¿”ã—ã¾ã™")
    return chunks.slice(0, 5)
  }

  return results.map((item) => item.chunk)
}

// GPTã‚’ä½¿ç”¨ã—ã¦è‡ªç„¶ãªå›ç­”ã‚’ç”Ÿæˆ
async function generateAnswerWithGPT(query: string, relevantChunks: DocumentChunk[]): Promise<string> {
  if (relevantChunks.length === 0) {
    return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFã‹ã‚‰ã”è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚ˆã‚Šå…·ä½“çš„ãªè³ªå•ã‚’ãŠè©¦ã—ã„ãŸã ãã‹ã€é–¢é€£ã™ã‚‹æ–‡æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
  }

  // OpenAI API keyãŒãªã„å ´åˆã¯ã‚·ãƒ³ãƒ—ãƒ«ãªå›ç­”ç”Ÿæˆ
  if (!process.env.OPENAI_API_KEY) {
    console.log("OpenAI API keyãŒãªã„ãŸã‚ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå›ç­”ç”Ÿæˆã‚’ä½¿ç”¨")
    return generateSimpleAnswer(query, relevantChunks)
  }

  try {
    // ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
    const context = relevantChunks
      .map((chunk, index) => {
        return `ã€å‡ºå…¸${index + 1}: ${chunk.metadata.filename} ãƒšãƒ¼ã‚¸${chunk.metadata.page}ã€‘\n${chunk.content}`
      })
      .join("\n\n")

    console.log("GPTã§å›ç­”ã‚’ç”Ÿæˆä¸­...")

    // OpenAI providerã«API keyã‚’æ˜ç¤ºçš„ã«æ¸¡ã™
    const openaiProvider = openai({
      apiKey: process.env.OPENAI_API_KEY,
    })

    const { text } = await generateText({
      model: openaiProvider("gpt-4o"),
      system: `ã‚ãªãŸã¯å¹´æ¬¡å ±å‘Šæ›¸ã®å°‚é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚æä¾›ã•ã‚ŒãŸPDFæ–‡æ›¸ã®å†…å®¹ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ã€è³ªå•ã«æ­£ç¢ºã‹ã¤è©³ç´°ã«ç­”ãˆã¦ãã ã•ã„ã€‚

é‡è¦ãªæŒ‡ç¤ºï¼š
1. æä¾›ã•ã‚ŒãŸæ–‡æ›¸ã®å†…å®¹ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
2. æ–‡æ›¸ã«è¨˜è¼‰ã•ã‚Œã¦ã„ãªã„æƒ…å ±ã¯æ¨æ¸¬ã—ãªã„ã§ãã ã•ã„
3. æ•°å€¤ã‚„å…·ä½“çš„ãªæƒ…å ±ã¯æ­£ç¢ºã«å¼•ç”¨ã—ã¦ãã ã•ã„
4. å›ç­”ã«ã¯å‡ºå…¸ï¼ˆãƒšãƒ¼ã‚¸ç•ªå·ï¼‰ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„
5. æ–‡æ›¸ã‹ã‚‰ç­”ãˆã‚‰ã‚Œãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜ç¢ºã«è¿°ã¹ã¦ãã ã•ã„`,
      prompt: `ä»¥ä¸‹ã®æ–‡æ›¸å†…å®¹ã‚’å‚è€ƒã«ã€è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã€è³ªå•ã€‘
${query}

ã€å‚è€ƒæ–‡æ›¸ã€‘
${context}

ã€å›ç­”ã€‘`,
      temperature: 0.1,
    })

    return text
  } catch (error) {
    console.error("GPTå›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼:", error)
    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒ³ãƒ—ãƒ«ãªå›ç­”ç”Ÿæˆ
    return generateSimpleAnswer(query, relevantChunks)
  }
}

// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªå›ç­”ç”Ÿæˆ
function generateSimpleAnswer(query: string, relevantChunks: DocumentChunk[]): string {
  let answer = `ã€Œ${query}ã€ã«é–¢ã—ã¦ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚\n\n`

  relevantChunks.forEach((chunk, index) => {
    if (index === 0) {
      answer += `${chunk.metadata.filename}ã®ãƒšãƒ¼ã‚¸${chunk.metadata.page}ã«ã‚ˆã‚‹ã¨ï¼š\n${chunk.content}\n`
    } else {
      answer += `\né–¢é€£æƒ…å ±ã¨ã—ã¦ã€ãƒšãƒ¼ã‚¸${chunk.metadata.page}ã§ã¯ï¼š\n${chunk.content}\n`
    }
  })

  return answer
}

// ãƒ¡ã‚¤ãƒ³ã®RAGå®Ÿè¡Œé–¢æ•°
export async function performRag(query: string, selectedDocIds: number[] = []): Promise<RagResult> {
  console.log(`\nğŸ” RAGå®Ÿè¡Œ: "${query}"`)

  try {
    if (selectedDocIds.length === 0) {
      return {
        answer: "æ¤œç´¢å¯¾è±¡ã®PDFãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚PDFã‚’é¸æŠã—ã¦ã‹ã‚‰è³ªå•ã—ã¦ãã ã•ã„ã€‚",
        sources: [],
        selectedDocuments: [],
      }
    }

    // å®Ÿéš›ã®PDFãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—
    const allChunks = await getDocumentChunks(selectedDocIds)
    console.log(`å–å¾—ã—ãŸãƒãƒ£ãƒ³ã‚¯: ${allChunks.length}å€‹`)

    if (allChunks.length === 0) {
      return {
        answer:
          "é¸æŠã•ã‚ŒãŸPDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚PDFãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
        sources: [],
        selectedDocuments: [],
      }
    }

    // ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
    const relevantChunks = await findRelevantChunksByVector(query, allChunks, 5)

    if (relevantChunks.length === 0) {
      return {
        answer: `ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFã‹ã‚‰ã€Œ${query}ã€ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\nåˆ©ç”¨å¯èƒ½ãªãƒšãƒ¼ã‚¸æ•°: ${Math.max(...allChunks.map((c) => c.metadata.page))}ãƒšãƒ¼ã‚¸\n\nåˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã—ã¦ã¿ã¦ãã ã•ã„ã€‚`,
        sources: [],
        selectedDocuments: [...new Set(allChunks.map((c) => c.metadata.filename))],
      }
    }

    // GPTã§è‡ªç„¶ãªå›ç­”ã‚’ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
    const answer = await generateAnswerWithGPT(query, relevantChunks)

    // å‡ºå…¸æƒ…å ±
    const sources = relevantChunks.map((chunk) => ({
      filename: chunk.metadata.filename,
      page: chunk.metadata.page,
      text: chunk.content,
      url: chunk.metadata.url,
    }))

    return {
      answer,
      sources,
      selectedDocuments: [...new Set(relevantChunks.map((c) => c.metadata.filename))],
    }
  } catch (error) {
    console.error("RAG error:", error)
    throw new Error("å›ç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
  }
}

// ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡ã®çµæœã‚’å–å¾—ã™ã‚‹é–¢æ•°
export async function getDocumentClassification(
  query: string,
  selectedDocIds: number[],
): Promise<{ documents: any[]; reasoning: string }> {
  const uploadedDocuments = await getUploadedDocuments(selectedDocIds)

  const hasApiKey = !!process.env.OPENAI_API_KEY
  let reasoning = `RAGåˆ†æ (${hasApiKey ? "ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢" : "æ”¹å–„ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"}):\n`
  reasoning += `- è³ªå•: "${query}"\n`
  reasoning += `- æ¤œç´¢å¯¾è±¡PDFæ•°: ${uploadedDocuments.length}\n`
  reasoning += `- å‡¦ç†æ–¹æ³•: ${hasApiKey ? "OpenAI Embeddingã§ãƒ™ã‚¯ãƒˆãƒ«åŒ– â†’ ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§æ¤œç´¢ â†’ GPT-4oã§å›ç­”ç”Ÿæˆ" : "åŒç¾©èªè¾æ›¸ + è²¡å‹™ç”¨èªèªè­˜ + æŸ”è»Ÿãªãƒãƒƒãƒãƒ³ã‚° â†’ ã‚·ãƒ³ãƒ—ãƒ«ãªå›ç­”ç”Ÿæˆ"}\n`
  reasoning += uploadedDocuments.map((doc) => `- ${doc.filename}`).join("\n")

  return {
    documents: uploadedDocuments,
    reasoning: reasoning,
  }
}
